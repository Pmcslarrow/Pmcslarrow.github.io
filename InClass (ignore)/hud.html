<!DOCTYPE html>

<html>
  <head></head>
  
  <body>
    The article, "Justice Department Secures Groundbreaking Settlement Agreement with Meta Platforms, 
    Formerly Known as Facebook, to Resolve Allegations of Discriminatory Advertising" brings up a controversial topic caused by Meta
    but introduces a topic that should be investigated in all organizations that introduce ad algorithms. The concerning part about Meta's algorithm 
    was not the fact that they used information such as "race, national origin and sex" to come to their conclusions, it was more the fact of how they actually
    used this information to create conclusions.
    </br>
  
    To further elaborate, the machine learning algorithm that Meta used was a function that is important in the field of Marketing. 
    When going through the marketing funnel, it is important to keep characteristics such as race, national origin, and sex, not as a way
    of creating your final decision for your product or ads, but rather as a way to hear the VoC better. When an organziation is segmenting, targeting,
    and positioning, they will in fact need to use characteristics such as the ones mentioned previously to more accurately create value for consumers, however,
    Meta failed to use this information in a progressive manor and rather used it as a binary decision (give them an ad based on these characteristics or not). 
    It brings up the question to whether this was a technology decision or whether it was a marketing decision to make it binary. Meta should have used these
    characteristics in the ways that were mentioned previously, although, more importantly, they should have used meta-data that exists within Meta
    platforms that relate to their customer's personalities and desires and then make a decision based on these traits, rather than on their physical characteristics.
    </br>
  
    Facebook mentions in, "Housing Department Slaps Facebook With Discrimination Charge", that they are "eager to find a solution". It brings up the question
    of how Facebook is able to get away with a scenario as large as this by acting as if they were unaware with the implementation. At the end of the day, 
    a machine learning algorithm is trained by a large dataset to make its decisions based on the data and constraints provided by Facebook. Somewhere 
    within the algorithm, they had to have said or had a measurement that makes the decision to share housing ads to individuals based on things like their
    ZIP Code. While I am happy that the issue is being addressed head on, I think that Facebook and other larger organizations need to be kept more accountable
    on issues such as this, that so directly influence and discriminate against a specific group of individuals. 
    
  </body>
  
</html>
